# Translation
### Statistical Machine Translation(SMT)
较为传统的基于条件概率的机器翻译，及找到target在source给定的条件下最大概率的取值作为翻译结果。数学理论基于贝叶斯论，如下图表示。
![avatar](https://github.com/coderGray1296/NLP/blob/master/cs224n/pictures/6.1.png)
通过贝叶斯将后验概率转换为两个独立项的乘积即可分别求解。蓝色部分为翻译模型，展示了词和句子如何被翻译的，通过平行语料库学习。绿色部分为语言模型，主要作用是写好英文翻译结果，从单体语料库学习。
那么如何获得概率最大的序列Y作为翻译结果呢？
![avatar](https://github.com/coderGray1296/NLP/blob/master/cs224n/pictures/6.2.png)
通过启发式搜索算法去寻找最佳的翻译结果，在这个过程中丢弃那些条件概率低的假设。
下面是SMT的decoding过程的一个例子，通过不断的剪枝操作，使得搜索树结构的效率更高。
![avatar](https://github.com/coderGray1296/NLP/blob/master/cs224n/pictures/6.3.png)
### Neural Machine Translation(NMT)
神经机器翻译是通过一个单一的神经网络去进行机器翻译。这个神经网络结构叫做sequence-to-sequence(seq2seq)，包含两个RNN。
##### The seq2seq model
下图展示了如何进行test阶段
![avatar](https://github.com/coderGray1296/NLP/blob/master/cs224n/pictures/6.4.png)
然而seq2seq并不仅限于MT task
![avatar](https://github.com/coderGray1296/NLP/blob/master/cs224n/pictures/6.5.png)
